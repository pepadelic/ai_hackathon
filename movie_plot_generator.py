import streamlit as st
import requests
import PyPDF2
import io
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
from typing import List, Dict
import json
import time
from datetime import datetime

# Configuration
URL = "https://granite-32-8b-instruct-apodhrad-test.apps.cluster-7r2vd.7r2vd.sandbox1120.opentlc.com"
CHAT_URL = f"{URL}/v1/chat/completions"

# Initialize session state
if 'vector_store' not in st.session_state:
    st.session_state.vector_store = None
if 'document_chunks' not in st.session_state:
    st.session_state.document_chunks = []
if 'embeddings_model' not in st.session_state:
    st.session_state.embeddings_model = None
if 'document_uploaded' not in st.session_state:
    st.session_state.document_uploaded = False
if 'generated_plots' not in st.session_state:
    st.session_state.generated_plots = []

@st.cache_resource
def load_embeddings_model():
    """Load the sentence transformer model for embeddings with error handling"""
    try:
        import warnings
        warnings.filterwarnings("ignore", message=".*Torch.*")
        warnings.filterwarnings("ignore", message=".*torch.*")
        
        import torch
        # Set torch to use minimal warnings
        torch.set_warn_always(False)
        
        st.info("ğŸ”„ NaÄÃ­tÃ¡m model pro vektorovÃ¡ embeddings (all-MiniLM-L6-v2)...")
        model = SentenceTransformer('all-MiniLM-L6-v2')
        st.success("âœ… Model pro embeddings byl ÃºspÄ›Å¡nÄ› naÄten!")
        return model
    except Exception as e:
        st.error(f"âŒ NepodaÅ™ilo se naÄÃ­st SentenceTransformer model: {str(e)}")
        st.info("ğŸ’¡ ZkouÅ¡Ã­m alternativnÃ­ pÅ™Ã­stup s TF-IDF...")
        
        try:
            # Fallback to a simpler approach using sklearn
            from sklearn.feature_extraction.text import TfidfVectorizer
            st.success("âœ… PouÅ¾Ã­vÃ¡m TF-IDF vektorizÃ¡tor jako nÃ¡hradu")
            return TfidfVectorizer(max_features=1000, stop_words='english')
        except ImportError:
            st.error("âŒ NepodaÅ™ilo se naÄÃ­st Å¾Ã¡dnÃ½ model pro embeddings. Nainstalujte potÅ™ebnÃ© zÃ¡vislosti.")
            return None

def extract_text_from_pdf(pdf_file) -> str:
    """Extract text content from uploaded PDF file with multiple fallback methods"""
    text = ""
    successful_pages = 0
    total_pages = 0
    
    # Reset file pointer to beginning
    pdf_file.seek(0)
    
    # Method 1: Try PyMuPDF first (most robust)
    try:
        import fitz  # PyMuPDF
        pdf_file.seek(0)
        
        pdf_bytes = pdf_file.read()
        pdf_document = fitz.open(stream=pdf_bytes, filetype="pdf")
        total_pages = pdf_document.page_count
        
        st.info(f"ğŸ“„ ZpracovÃ¡vÃ¡m PDF s {total_pages} strÃ¡nkami pomocÃ­ PyMuPDF...")
        
        for page_num in range(total_pages):
            try:
                page = pdf_document[page_num]
                page_text = page.get_text()
                if page_text and page_text.strip():
                    text += page_text + "\n"
                    successful_pages += 1
            except Exception as page_error:
                st.warning(f"âš ï¸ NepodaÅ™ilo se extrahovat text ze strÃ¡nky {page_num + 1} s PyMuPDF: {str(page_error)}")
                continue
        
        pdf_document.close()
        
        if text.strip():
            st.success(f"âœ… Text extrahovÃ¡n pomocÃ­ PyMuPDF ({successful_pages}/{total_pages} strÃ¡nek ÃºspÄ›Å¡nÄ›)")
            return text
            
    except ImportError:
        st.info("ğŸ’¡ Instaluji PyMuPDF pro lepÅ¡Ã­ podporu PDF...")
    except Exception as e:
        st.warning(f"âš ï¸ PyMuPDF extrakce selhala: {str(e)}. ZkouÅ¡Ã­m alternativnÃ­ metodu...")
    
    # Method 2: Try with pdfplumber as fallback
    try:
        import pdfplumber
        pdf_file.seek(0)
        text = ""  # Reset text
        successful_pages = 0
        
        with pdfplumber.open(pdf_file) as pdf:
            total_pages = len(pdf.pages)
            st.info(f"ğŸ“„ ZkouÅ¡Ã­m pdfplumber extrakci pro {total_pages} strÃ¡nek...")
            
            for page_num, page in enumerate(pdf.pages):
                try:
                    page_text = page.extract_text()
                    if page_text and page_text.strip():
                        text += page_text + "\n"
                        successful_pages += 1
                except Exception as page_error:
                    st.warning(f"âš ï¸ NepodaÅ™ilo se extrahovat text ze strÃ¡nky {page_num + 1} s pdfplumber: {str(page_error)}")
                    continue
        
        if text.strip():
            st.success(f"âœ… Text extrahovÃ¡n pomocÃ­ pdfplumber ({successful_pages}/{total_pages} strÃ¡nek ÃºspÄ›Å¡nÄ›)")
            return text
            
    except ImportError:
        st.info("ğŸ’¡ pdfplumber nenÃ­ dostupnÃ½, zkouÅ¡Ã­m PyPDF2...")
    except Exception as e:
        st.warning(f"âš ï¸ pdfplumber extrakce takÃ© selhala: {str(e)}. ZkouÅ¡Ã­m PyPDF2...")
    
    # Method 3: Try PyPDF2 as last resort with better error handling
    try:
        pdf_file.seek(0)
        text = ""  # Reset text
        successful_pages = 0
        
        # Try different PyPDF2 approaches
        pdf_reader = PyPDF2.PdfReader(pdf_file, strict=False)  # Use non-strict mode
        
        # Check if PDF is encrypted
        if pdf_reader.is_encrypted:
            st.error("âŒ PDF je chrÃ¡nÄ›no heslem. Nahrajte nechrÃ¡nÄ›nÃ½ PDF.")
            return ""
        
        total_pages = len(pdf_reader.pages)
        st.info(f"ğŸ“„ ZkouÅ¡Ã­m PyPDF2 extrakci pro {total_pages} strÃ¡nek (non-strict mÃ³d)...")
        
        # Extract text from all pages with better error handling
        for page_num, page in enumerate(pdf_reader.pages):
            try:
                # Try multiple extraction methods for each page
                page_text = ""
                
                # Method 3a: Standard extraction
                try:
                    page_text = page.extract_text()
                except:
                    pass
                
                # Method 3b: Try extracting with different parameters
                if not page_text or not page_text.strip():
                    try:
                        page_text = page.extract_text(extraction_mode="layout")
                    except:
                        pass
                
                if page_text and page_text.strip():
                    text += page_text + "\n"
                    successful_pages += 1
                else:
                    st.warning(f"âš ï¸ StrÃ¡nka {page_num + 1} se zdÃ¡ bÃ½t prÃ¡zdnÃ¡ nebo obsahuje pouze obrÃ¡zky")
                    
            except Exception as page_error:
                # Don't show warnings for every page failure with PyPDF2, just count them
                continue
        
        if text.strip():
            st.success(f"âœ… Text extrahovÃ¡n pomocÃ­ PyPDF2 ({successful_pages}/{total_pages} strÃ¡nek ÃºspÄ›Å¡nÄ›)")
            return text
        elif successful_pages == 0:
            st.warning("âš ï¸ PyPDF2 nemohl extrahovat text z Å¾Ã¡dnÃ© strÃ¡nky")
            
    except Exception as e:
        st.warning(f"âš ï¸ PyPDF2 extrakce takÃ© selhala: {str(e)}")
    
    # If all methods failed but we got some text
    if text.strip():
        st.success(f"âœ… ÄŒÃ¡steÄnÃ¡ extrakce textu ÃºspÄ›Å¡nÃ¡ ({successful_pages}/{total_pages} strÃ¡nek)")
        return text
    
    # If completely failed
    st.error("""
    âŒ **NepodaÅ™ilo se extrahovat text z PDF**
    
    **MoÅ¾nÃ© dÅ¯vody:**
    - PDF obsahuje pouze obrÃ¡zky/skenovanÃ½ obsah (Å¾Ã¡dnÃ½ extrahovatelnÃ½ text)
    - PDF mÃ¡ neobvyklÃ© kÃ³dovÃ¡nÃ­ nebo je vÃ¡Å¾nÄ› poÅ¡kozenÃ½
    - PDF pouÅ¾Ã­vÃ¡ nestandardnÃ­ fonty nebo sloÅ¾itÃ© formÃ¡tovÃ¡nÃ­
    
    **NÃ¡vrhy:**
    - Zkuste jinÃ½ PDF soubor se standardnÃ­m textovÃ½m obsahem
    - PouÅ¾ijte OCR nÃ¡stroje pro pÅ™evod skenovanÃ½ch PDF na text-prohledÃ¡vatelnÃ© PDF
    - Zkuste otevÅ™Ã­t PDF v jinÃ© aplikaci a znovu jej uloÅ¾it
    - Zkontrolujte, zda se PDF sprÃ¡vnÄ› zobrazuje v prohlÃ­Å¾eÄi PDF
    """)
    return ""

def chunk_text(text: str, chunk_size: int = 1000, overlap: int = 200) -> List[str]:
    """Split text into overlapping chunks"""
    chunks = []
    start = 0
    
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        
        # Try to break at sentence boundary
        if end < len(text):
            last_period = chunk.rfind('.')
            last_newline = chunk.rfind('\n')
            break_point = max(last_period, last_newline)
            
            if break_point > start + chunk_size // 2:
                chunk = text[start:break_point + 1]
                end = break_point + 1
        
        chunks.append(chunk.strip())
        start = end - overlap
        
        if start >= len(text):
            break
    
    return [chunk for chunk in chunks if len(chunk.strip()) > 50]

def create_vector_store(chunks: List[str], model) -> faiss.IndexFlatIP:
    """Create FAISS vector store from text chunks"""
    if not chunks:
        return None, []
    
    # Generate embeddings
    with st.spinner("VytvÃ¡Å™Ã­m embeddings..."):
        embeddings = model.encode(chunks, show_progress_bar=True)
    
    # Normalize embeddings for cosine similarity
    embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)
    
    # Create FAISS index
    dimension = embeddings.shape[1]
    index = faiss.IndexFlatIP(dimension)
    index.add(embeddings.astype('float32'))
    
    return index, embeddings

def retrieve_relevant_chunks(query: str, model, vector_store, chunks: List[str], k: int = 5) -> List[str]:
    """Retrieve most relevant chunks for a given query"""
    if not vector_store or not chunks:
        return []
    
    # Generate query embedding
    query_embedding = model.encode([query])
    query_embedding = query_embedding / np.linalg.norm(query_embedding, axis=1, keepdims=True)
    
    # Search for similar chunks
    scores, indices = vector_store.search(query_embedding.astype('float32'), k)
    
    # Return relevant chunks
    relevant_chunks = []
    for i, idx in enumerate(indices[0]):
        if scores[0][i] > 0.1:  # Similarity threshold
            relevant_chunks.append(chunks[idx])
    
    return relevant_chunks

def call_llm(messages: List[Dict], max_retries: int = 5) -> str:
    """Call the LLM API with enhanced retry logic and exponential backoff"""
    headers = {
        "Content-Type": "application/json"
    }
    
    # Try with different configurations for better success rate
    configurations = [
        {
            "model": "granite-32-8b-instruct",
            "messages": messages,
            "temperature": 0.8,
            "max_tokens": 1500,
            "stream": False
        },
        {
            "model": "granite-32-8b-instruct", 
            "messages": messages,
            "temperature": 0.7,
            "max_tokens": 1000,
            "stream": False
        },
        {
            "model": "granite-32-8b-instruct",
            "messages": messages, 
            "temperature": 0.6,
            "max_tokens": 800,
            "stream": False
        }
    ]
    
    for config_idx, payload in enumerate(configurations):
        st.info(f"ğŸ”„ ZkouÅ¡Ã­m konfiguraci {config_idx + 1}/3...")
        
        for attempt in range(max_retries):
            try:
                # Exponential backoff delay
                if attempt > 0:
                    delay = min(2 ** attempt, 30)  # Max 30 seconds
                    st.info(f"â³ ÄŒekÃ¡m {delay} sekund pÅ™ed dalÅ¡Ã­m pokusem...")
                    time.sleep(delay)
                
                # Adjust timeout based on attempt
                timeout = 30 + (attempt * 15)  # Start with 30s, increase each attempt
                
                st.info(f"ğŸ“¡ OdesÃ­lÃ¡m poÅ¾adavek na LLM API (pokus {attempt + 1}/{max_retries}, timeout: {timeout}s)...")
                
                response = requests.post(
                    CHAT_URL,
                    headers=headers,
                    json=payload,
                    timeout=timeout
                )
                
                if response.status_code == 200:
                    result = response.json()
                    st.success("âœ… ÃšspÄ›Å¡nÄ› zÃ­skÃ¡na odpovÄ›Ä od LLM!")
                    return result['choices'][0]['message']['content']
                elif response.status_code == 504:
                    st.warning(f"âš ï¸ Server timeout (504) - pokus {attempt + 1}/{max_retries}")
                    if attempt == max_retries - 1:
                        st.error("âŒ Server je pÅ™etÃ­Å¾enÃ½ nebo nedostupnÃ½. Zkuste to za chvÃ­li.")
                    continue
                elif response.status_code == 503:
                    st.warning(f"âš ï¸ SluÅ¾ba nedostupnÃ¡ (503) - pokus {attempt + 1}/{max_retries}")
                    continue
                elif response.status_code == 502:
                    st.warning(f"âš ï¸ Bad Gateway (502) - pokus {attempt + 1}/{max_retries}")
                    continue
                else:
                    st.warning(f"âš ï¸ API chyba: {response.status_code} - pokus {attempt + 1}/{max_retries}")
                    if attempt == max_retries - 1:
                        return f"""âŒ **NepodaÅ™ilo se zÃ­skat odpovÄ›Ä od LLM**
                        
**Stav chyby:** {response.status_code}
**Popis:** {response.text if len(response.text) < 200 else response.text[:200] + '...'}

**Co mÅ¯Å¾ete zkusit:**
- Zkuste to za nÄ›kolik minut znovu
- Vyberte jinÃ½ Å¾Ã¡nr
- Zkontrolujte pÅ™ipojenÃ­ k internetu
- Server mÅ¯Å¾e bÃ½t pÅ™etÃ­Å¾enÃ½"""
                    
            except requests.exceptions.Timeout:
                st.warning(f"â° ÄŒasovÃ½ limit poÅ¾adavku pÅ™ekroÄen (pokus {attempt + 1}/{max_retries})")
                if attempt == max_retries - 1 and config_idx == len(configurations) - 1:
                    return """âŒ **ÄŒasovÃ½ limit poÅ¾adavku pÅ™ekroÄen**
                    
**MoÅ¾nÃ© Å™eÅ¡enÃ­:**
- Server je pÅ™Ã­liÅ¡ pomalÃ½ nebo pÅ™etÃ­Å¾enÃ½
- Zkuste to za nÄ›kolik minut
- MoÅ¾nÃ¡ je problÃ©m s pÅ™ipojenÃ­m k internetu
- Kontaktujte sprÃ¡vce API pokud problÃ©m pÅ™etrvÃ¡vÃ¡"""
                    
            except requests.exceptions.ConnectionError:
                st.warning(f"ğŸ”Œ Chyba pÅ™ipojenÃ­ (pokus {attempt + 1}/{max_retries})")
                if attempt == max_retries - 1 and config_idx == len(configurations) - 1:
                    return """âŒ **Chyba pÅ™ipojenÃ­ k serveru**
                    
**MoÅ¾nÃ© Å™eÅ¡enÃ­:**
- Zkontrolujte pÅ™ipojenÃ­ k internetu
- Server mÅ¯Å¾e bÃ½t doÄasnÄ› nedostupnÃ½
- Zkuste to za nÄ›kolik minut
- MoÅ¾nÃ¡ je problÃ©m s API endpointem"""
                    
            except Exception as e:
                st.warning(f"â“ NeoÄekÃ¡vanÃ¡ chyba: {str(e)} (pokus {attempt + 1}/{max_retries})")
                if attempt == max_retries - 1 and config_idx == len(configurations) - 1:
                    return f"""âŒ **NeoÄekÃ¡vanÃ¡ chyba**
                    
**Popis chyby:** {str(e)}

**Co mÅ¯Å¾ete zkusit:**
- Zkuste to znovu za chvÃ­li
- Restartujte aplikaci
- Zkontrolujte, zda jsou nainstalovÃ¡ny vÅ¡echny zÃ¡vislosti"""
    
    return """âŒ **NepodaÅ™ilo se vygenerovat zÃ¡pletku**
    
VÅ¡echny pokusy o spojenÃ­ s AI selhal. Zkuste to prosÃ­m pozdÄ›ji nebo kontaktujte sprÃ¡vce systÃ©mu."""

def generate_fallback_plot(genre: str) -> str:
    """Generate a simple fallback plot when API is unavailable"""
    import random
    
    # Simple plot templates for each genre
    plot_templates = {
        "AkÄnÃ­": [
            "BÃ½valÃ½ vojÃ¡k {name1} musÃ­ zachrÃ¡nit svou unesenou dceru z rukou nebezpeÄnÃ©ho zloÄineckÃ©ho syndikÃ¡tu. S pomocÃ­ svÃ© kolegynÄ› {name2} se vydÃ¡vÃ¡ na nebezpeÄnou misi plnou stÅ™elby a honÅ¯. PostupnÄ› odhaluje, Å¾e za Ãºnosem stojÃ­ jeho bÃ½valÃ½ pÅ™Ã­tel, kterÃ½ se stal zrÃ¡dcem.",
            "PolicejnÃ­ detektiv {name1} objevÃ­ spiknutÃ­ proti vlÃ¡dÄ›. SpoleÄnÄ› s reportÃ©rkou {name2} se snaÅ¾Ã­ odhalit pravdu, zatÃ­mco je pronÃ¡sledujÃ­ nÃ¡jemnÃ­ vrazi. NapÃ­navÃ¡ honiÄka konÄÃ­ velkÃ½m odhalenÃ­m korupce na nejvyÅ¡Å¡Ã­ch mÃ­stech."
        ],
        "Komedie": [
            "NeÃºspÄ›Å¡nÃ½ herec {name1} se omylem vydÃ¡vÃ¡ za slavnÃ©ho reÅ¾isÃ©ra. S pomocÃ­ svÃ© pÅ™Ã­telkynÄ› {name2} se snaÅ¾Ã­ udrÅ¾et tuto leÅ¾, coÅ¾ vede k Å™adÄ› vtipnÃ½ch situacÃ­. Nakonec dÃ­ky svÃ© upÅ™Ã­mnosti zÃ­skÃ¡ skuteÄnou filmovou roli.",
            "Dva sousedÃ© {name1} a {name2} se neustÃ¡le hÃ¡dajÃ­ kvÅ¯li maliÄkostem. KdyÅ¾ musÃ­ spoleÄnÄ› organizovat sousedskou slavnost, jejich spory vedou k hilariÃ³znÃ­m nedorozumÄ›nÃ­m, ale nakonec se z nich stanou nejlepÅ¡Ã­ pÅ™Ã¡telÃ©."
        ],
        "Drama": [
            "MladÃ¡ uÄitelka {name1} pÅ™ichÃ¡zÃ­ do problÃ©movÃ© Å¡koly v pÅ™edmÄ›stÃ­. PostupnÄ› zÃ­skÃ¡vÃ¡ dÅ¯vÄ›ru svÃ½ch studentÅ¯, vÄetnÄ› rebelskÃ©ho {name2}, a pomÃ¡hÃ¡ jim najÃ­t cestu k lepÅ¡Ã­ budoucnosti. JejÃ­ odhodlÃ¡nÃ­ mÄ›nÃ­ Å¾ivoty celÃ© komunity.",
            "Otec {name1} se po letech snaÅ¾Ã­ znovu navÃ¡zat vztah se svÃ½m odcizenÃ½m synem {name2}. Jejich spoleÄnÃ¡ cesta je plnÃ¡ emocÃ­, vzpomÃ­nek a postupnÃ©ho odpuÅ¡tÄ›nÃ­. Nakonec pochopÃ­, jak moc si navzÃ¡jem chybÃ­."
        ],
        "Horor": [
            "Skupina pÅ™Ã¡tel se nastÄ›huje do starÃ©ho domu, kterÃ½ skrÃ½vÃ¡ temnÃ© tajemstvÃ­. PostupnÄ› descobujÃ­, Å¾e dÅ¯m je prokletÃ½ a jeho pÅ™edchozÃ­ obyvatelÃ© zde zahynuli za zÃ¡hadnÃ½ch okolnostÃ­. {name1} musÃ­ najÃ­t zpÅ¯sob, jak prokletÃ­ zlomit.",
            "V malÃ©m mÄ›steÄku se zaÄnou dÃ­t podivnÃ© vÄ›ci. Psycholog {name1} vyÅ¡etÅ™uje sÃ©rii zÃ¡hadnÃ½ch zmizenÃ­ a zjiÅ¡Å¥uje, Å¾e za vÅ¡Ã­m stojÃ­ nadpÅ™irozenÃ¡ sÃ­la. S pomocÃ­ mÃ­stnÃ­ knihovnice {name2} hledÃ¡ zpÅ¯sob, jak zlo zastavit."
        ],
        "Sci-Fi": [
            "V roce 2150 objevÃ­ vÄ›dkynÄ› {name1} portÃ¡l do paralelnÃ­ho vesmÃ­ru. SpoleÄnÄ› s kolegou {name2} prozkoumÃ¡vÃ¡ alternativnÃ­ realitu, kde lidstvo vyvinulo odliÅ¡nou technologii. MusÃ­ se rozhodnout, zda zÅ¯stat nebo se vrÃ¡tit domÅ¯.",
            "Astronaut {name1} se po dlouhÃ© misi vracÃ­ na Zemi a zjiÅ¡Å¥uje, Å¾e se planeta zmÄ›nila k nepoznÃ¡nÃ­. S pomocou rebelky {name2} se snaÅ¾Ã­ pochopit, co se stalo, a bojuje za obnovu pÅ¯vodnÃ­ho svÄ›ta."
        ],
        "Fantasy": [
            "MladÃ½ ÄarodÄ›j {name1} objevÃ­, Å¾e je potomkem mocnÃ© ÄarodÄ›jnÃ© dynastie. S prÅ¯vodkynÃ­ {name2} se vydÃ¡vÃ¡ na nebezpeÄnou cestu, aby zÃ­skal svÃ© dÄ›dictvÃ­ a porazil temnÃ©ho mÃ¡ga, kterÃ½ ohroÅ¾uje krÃ¡lovstvÃ­.",
            "V svÄ›tÄ›, kde magie mizÃ­, poslednÃ­ ÄarodÄ›jnice {name1} musÃ­ najÃ­t zpÅ¯sob, jak ji zachrÃ¡nit. SpoleÄnÄ› s elfskÃ½m vÃ¡leÄnÃ­kem {name2} hledÃ¡ pradÃ¡vnÃ½ artefakt, kterÃ½ mÅ¯Å¾e obnovit magickou rovnovÃ¡hu."
        ],
        "RomantickÃ½": [
            "ÃšspÄ›Å¡nÃ¡ architektka {name1} se vracÃ­ do rodnÃ©ho mÄ›steÄka a znovu potkÃ¡vÃ¡ svou stÅ™edoÅ¡kolskou lÃ¡sku {name2}. Jejich cesty se rozdÄ›lily, ale osudy je znovu spojujÃ­. MusÃ­ se rozhodnout mezi kariÃ©rou a lÃ¡skou.",
            "Dva lidÃ© {name1} a {name2} se potkÃ¡vajÃ­ kaÅ¾dÃ½ den v kavÃ¡rnÄ›, aniÅ¾ by spolu mluvili. KdyÅ¾ se koneÄnÄ› odvÃ¡Å¾Ã­ promluvit, zjistÃ­, Å¾e majÃ­ mnoho spoleÄnÃ©ho a zaÄÃ­nÃ¡ krÃ¡snÃ½ pÅ™Ã­bÄ›h lÃ¡sky."
        ],
        "Thriller": [
            "PsycholoÅ¾ka {name1} lÃ©ÄÃ­ pacienta s poruchou pamÄ›ti, ale postupnÄ› zjiÅ¡Å¥uje, Å¾e je svÄ›dkem vraÅ¾dy. S detektivem {name2} se snaÅ¾Ã­ odhalit pravdu, zatÃ­mco ji nÄ›kdo pronÃ¡sleduje a ohroÅ¾uje.",
            "NovinÃ¡Å™ {name1} vyÅ¡etÅ™uje sÃ©rii zÃ¡hadnÃ½ch ÃºmrtÃ­. Stopy vedou k mocnÃ© korporaci, kde pracuje jeho pÅ™Ã­telkynÄ› {name2}. MusÃ­ zjistit pravdu, aniÅ¾ by ohrozil sebe i ji."
        ],
        "Krimi": [
            "Detektiv {name1} vyÅ¡etÅ™uje vraÅ¾du, kterÃ¡ pÅ™ipomÃ­nÃ¡ pÅ™Ã­pad z jeho minulosti. S novou partnerkou {name2} objevuje souvislosti, kterÃ© vedou k osobnÃ­ vendettÄ›. MusÃ­ Äelit vlastnÃ­m dÃ©monÅ¯m.",
            "BÃ½valÃ½ zloÄinec {name1} se snaÅ¾Ã­ zaÄÃ­t novÃ½ Å¾ivot, ale jeho minulost ho dostihne. S pomocÃ­ advokÃ¡tky {name2} bojuje proti faleÅ¡nÃ½m obvinÄ›nÃ­m a hledÃ¡ skuteÄnÃ©ho vinÃ­ka."
        ],
        "HistorickÃ½": [
            "V dobÄ› ÄeskÃ©ho nÃ¡rodnÃ­ho obrozenÃ­ se mladÃ½ spisovatel {name1} zapojuje do boje za nezÃ¡vislost. S vlastenkou {name2} organizujÃ­ tajnÃ© setkÃ¡nÃ­ a Å¡Ã­Å™Ã­ zakÃ¡zanÃ© texty. Jejich lÃ¡ska pÅ™ekonÃ¡vÃ¡ vÅ¡echny pÅ™ekÃ¡Å¾ky.",
            "BÄ›hem druhÃ© svÄ›tovÃ© vÃ¡lky pomÃ¡hÃ¡ lÃ©kaÅ™ka {name1} partyzÃ¡nÅ¯m. S dÅ¯stojnÃ­kem {name2} zachraÅˆuje ranÄ›nÃ© a ukrÃ½vÃ¡ pronÃ¡sledovanÃ©. Jejich odvaha mÄ›nÃ­ osudy mnoha lidÃ­."
        ],
        "VÃ¡leÄnÃ½": [
            "MladÃ½ vojÃ¡k {name1} se bÄ›hem vÃ¡lky ocitÃ¡ odÅ™Ã­znut od svÃ© jednotky. S mÃ­stnÃ­ obyvatelkou {name2} se snaÅ¾Ã­ pÅ™eÅ¾Ã­t v nepÅ™Ã¡telskÃ©m ÃºzemÃ­. Jejich spoleÄnÃ½ boj odhaluje skuteÄnou povahu humanity.",
            "VeterÃ¡n {name1} se vracÃ­ z vÃ¡lky zmÄ›nÄ›nÃ½. S pomocÃ­ terapeutky {name2} se snaÅ¾Ã­ vyrovnat s traumatem a najÃ­t mÃ­sto v civilnÃ­m svÄ›tÄ›. Jeho cesta k uzdravenÃ­ je dlouhÃ¡ ale povzbudivÃ¡."
        ],
        "Å½ivotopisnÃ½": [
            "PÅ™Ã­bÄ›h vÃ½jimeÄnÃ© Å¾eny {name1}, kterÃ¡ pÅ™es vÅ¡echny pÅ™ekÃ¡Å¾ky dosÃ¡hla svÃ©ho snu. S podporou svÃ©ho pÅ™Ã­tele {name2} pÅ™ekonÃ¡vÃ¡ spoleÄenskÃ© pÅ™edsudky a stÃ¡vÃ¡ se prÅ¯kopnicÃ­ ve svÃ©m oboru.",
            "MladÃ½ muÅ¾ {name1} z chudÃ½ch pomÄ›rÅ¯ se dÃ­ky svÃ©mu talentu a houÅ¾evnatosti dostÃ¡vÃ¡ na vrchol. Jeho pÅ™Ã­telkynÄ› {name2} ho podporuje ve vÅ¡ech tÄ›Å¾kÃ½ch chvÃ­lÃ­ch. Je to pÅ™Ã­bÄ›h o sÃ­le vÅ¯le a lÃ¡sce."
        ],
        "DobrodruÅ¾nÃ½": [
            "Archeolog {name1} objevÃ­ mapu vedoucÃ­ k ztracenÃ©mu pokladu. SpoleÄnÄ› s odvÃ¡Å¾nou prÅ¯vodkynÃ­ {name2} se vydÃ¡vÃ¡ na nebezpeÄnou expedici. MusÃ­ Äelit pÅ™Ã­rodnÃ­m katastrofÃ¡m i zlÃ½m konkurentÅ¯m.",
            "Pilot {name1} nouzovÄ› pÅ™istÃ¡vÃ¡ na nezmapovanÃ©m ostrovÄ›. S biologkou {name2} objevuje neznÃ¡mÃ© druhy a snaÅ¾Ã­ se najÃ­t cestu domÅ¯. Jejich dobrodruÅ¾stvÃ­ odhaluje krÃ¡sy i nebezpeÄÃ­ divoÄiny."
        ],
        "Western": [
            "OsamÄ›lÃ½ pistolnÃ­k {name1} pÅ™ijÃ­Å¾dÃ­ do mÄ›steÄka ovlÃ¡danÃ©ho bandity. S pomocÃ­ odvÃ¡Å¾nÃ© majitelky salonu {name2} organizuje odpor proti tyranii. Jejich boj za spravedlnost mÄ›nÃ­ celÃ© mÄ›sto.",
            "Å erif {name1} se musÃ­ postavit gangu, kterÃ½ terorizuje okolÃ­. Jeho partnerka {name2} mu pomÃ¡hÃ¡ udrÅ¾et poÅ™Ã¡dek. Je to pÅ™Ã­bÄ›h o odvaze a vÄ›rnosti zÃ¡konu."
        ],
        "MysteriÃ³znÃ­": [
            "Detektiv {name1} vyÅ¡etÅ™uje sÃ©rii podivnÃ½ch udÃ¡lostÃ­ v malÃ©m mÄ›stÄ›. S knihovnicÃ­ {name2} odhaluje tajemstvÃ­, kterÃ© sahÃ¡ hluboko do historie. Pravda je pÅ™ekvapivÄ›jÅ¡Ã­, neÅ¾ Äekali.",
            "Psycholog {name1} studuje paranormÃ¡lnÃ­ jevy a setkÃ¡vÃ¡ se s mÃ©diem {name2}. SpoleÄnÄ› zkoumajÃ­ nevysvÄ›tlitelnÃ© Ãºkazy a postupnÄ› odhalujÃ­ hranice mezi realitou a nadpÅ™irozenem."
        ]
    }
    
    # Generate random names
    czech_names = ["Anna", "Petr", "Marie", "Jan", "Eva", "TomÃ¡Å¡", "VÄ›ra", "Pavel", "Jana", "Martin", "Lucie", "JiÅ™Ã­", "Tereza", "David", "KateÅ™ina"]
    name1 = random.choice(czech_names)
    name2 = random.choice([n for n in czech_names if n != name1])
    
    # Select template and format
    if genre in plot_templates:
        template = random.choice(plot_templates[genre])
        return template.format(name1=name1, name2=name2)
    else:
        return f"PÅ™Ã­bÄ›h o {name1} a {name2} v Å¾Ã¡nru {genre} - bohuÅ¾el nemÃ¡m k dispozici Å¡ablonu pro tento Å¾Ã¡nr."

def generate_movie_plot(genre: str, good_reviews_context: str) -> dict:
    """Generate a movie plot based on genre and good reviews context"""
    
    # System prompt in Czech
    system_prompt = """Jsi kreativnÃ­ scenÃ¡rista, kterÃ½ vytvÃ¡Å™Ã­ zajÃ­mavÃ© a originÃ¡lnÃ­ filmovÃ© zÃ¡pletky v ÄeÅ¡tinÄ›. 
    TvÃ½m Ãºkolem je vytvoÅ™it poutavÃ½ pÅ™Ã­bÄ›h filmu na zÃ¡kladÄ› zvolenÃ©ho Å¾Ã¡nru a inspirovat se pozitivnÃ­mi recenzemi z poskytnutÃ©ho kontextu.
    
    Pravidla:
    - VÅ¾dy piÅ¡ POUZE v ÄeÅ¡tinÄ›
    - VytvoÅ™ originÃ¡lnÃ­ zÃ¡pletku (ne kopii existujÃ­cÃ­ho filmu)
    - ZÃ¡pletka by mÄ›la bÃ½t dlouhÃ¡ asi 200-300 slov
    - ZahrÅˆ hlavnÃ­ postavy, zÃ¡kladnÃ­ konflikt a nÃ¡znaÄ Å™eÅ¡enÃ­
    - Inspiruj se pozitivnÃ­mi aspekty z recenzÃ­ (co lidÃ© na filmech oceÅˆujÃ­)
    - BuÄ kreativnÃ­ a zajÃ­mavÃ½
    - NezmiÅˆuj konkrÃ©tnÃ­ nÃ¡zvy existujÃ­cÃ­ch filmÅ¯
    """
    
    user_prompt = f"""Å½Ã¡nr filmu: {genre}

Kontext z pozitivnÃ­ch recenzÃ­:
{good_reviews_context}

VytvoÅ™ originÃ¡lnÃ­ zÃ¡pletku pro novÃ½ film v Å¾Ã¡nru {genre}. Inspiruj se pozitivnÃ­mi aspekty z recenzÃ­ - co lidÃ© na filmech oceÅˆujÃ­ (napÅ™. dobrÃ© vztahy mezi postavami, napÄ›tÃ­, humor, emoce, pÅ™ekvapivÃ© zvraty, atd.).

ZÃ¡pletka filmu:"""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]
    
    # Prepare full prompt for debugging
    full_prompt = f"**SYSTEM PROMPT:**\n{system_prompt}\n\n**USER PROMPT:**\n{user_prompt}"
    
    # Try to get AI-generated plot
    ai_response = call_llm(messages)
    
    # If AI response contains error messages, use fallback
    if ai_response.startswith("âŒ") or "Chyba:" in ai_response or "NepodaÅ™ilo se" in ai_response:
        st.warning("âš ï¸ AI sluÅ¾ba nenÃ­ dostupnÃ¡, pouÅ¾Ã­vÃ¡m zÃ¡loÅ¾nÃ­ generÃ¡tor zÃ¡pletek...")
        fallback_plot = generate_fallback_plot(genre)
        final_plot = f"""ğŸ¤– **ZÃ¡loÅ¾nÃ­ zÃ¡pletka (AI nedostupnÃ¡)**

{fallback_plot}

---
*PoznÃ¡mka: Tato zÃ¡pletka byla vygenerovÃ¡na zÃ¡loÅ¾nÃ­m systÃ©mem, protoÅ¾e AI sluÅ¾ba nenÃ­ momentÃ¡lnÄ› dostupnÃ¡. Pro kvalitnÄ›jÅ¡Ã­ vÃ½sledky zkuste pozdÄ›ji, aÅ¾ bude AI sluÅ¾ba opÄ›t funkÄnÃ­.*"""
        
        return {
            'plot': final_plot,
            'raw_prompt': full_prompt,
            'raw_response': ai_response,
            'is_fallback': True
        }
    
    return {
        'plot': ai_response,
        'raw_prompt': full_prompt,
        'raw_response': ai_response,
        'is_fallback': False
    }

def main():
    st.set_page_config(
        page_title="GenerÃ¡tor filmovÃ½ch zÃ¡pletek",
        page_icon="ğŸ¬",
        layout="wide"
    )
    
    st.title("ğŸ¬ GenerÃ¡tor filmovÃ½ch zÃ¡pletek")
    st.markdown("Nahrajte PDF s filmovÃ½mi recenzemi a vygenerujte originÃ¡lnÃ­ zÃ¡pletku novÃ©ho filmu na zÃ¡kladÄ› zvolenÃ©ho Å¾Ã¡nru!")
    
    # Sidebar for document upload
    with st.sidebar:
        st.header("ğŸ“„ NahrÃ¡nÃ­ dokumentu")
        
        uploaded_file = st.file_uploader(
            "Vyberte PDF soubor",
            type="pdf",
            help="Nahrajte PDF s filmovÃ½mi recenzemi"
        )
        
        if uploaded_file is not None:
            if not st.session_state.document_uploaded or st.button("Zpracovat dokument"):
                with st.spinner("ZpracovÃ¡vÃ¡m dokument..."):
                    # Load embeddings model
                    if st.session_state.embeddings_model is None:
                        st.session_state.embeddings_model = load_embeddings_model()
                    
                    # Extract text from PDF
                    text = extract_text_from_pdf(uploaded_file)
                    
                    if text:
                        # Chunk the text
                        chunks = chunk_text(text)
                        st.session_state.document_chunks = chunks
                        
                        # Create vector store
                        vector_store, embeddings = create_vector_store(
                            chunks, st.session_state.embeddings_model
                        )
                        st.session_state.vector_store = vector_store
                        
                        st.session_state.document_uploaded = True
                        st.success(f"âœ… Dokument zpracovÃ¡n! VytvoÅ™eno {len(chunks)} ÄÃ¡stÃ­.")
                        
                        # Show document stats
                        st.info(f"""
                        **Statistiky dokumentu:**
                        - Celkem znakÅ¯: {len(text):,}
                        - PoÄet ÄÃ¡stÃ­: {len(chunks)}
                        - PrÅ¯mÄ›rnÃ¡ velikost ÄÃ¡sti: {len(text)//len(chunks) if chunks else 0} znakÅ¯
                        """)
                    else:
                        st.error("NepodaÅ™ilo se extrahovat text z PDF")
        
        # Clear document button
        if st.session_state.document_uploaded:
            if st.button("ğŸ—‘ï¸ Vymazat dokument"):
                st.session_state.vector_store = None
                st.session_state.document_chunks = []
                st.session_state.document_uploaded = False
                st.session_state.generated_plots = []
                st.rerun()
    
    # Main plot generation interface
    if st.session_state.document_uploaded:
        st.success("ğŸ“– Dokument naÄten a pÅ™ipraven pro generovÃ¡nÃ­ zÃ¡pletek!")
        
        # Genre selection
        st.subheader("ğŸ­ VÃ½bÄ›r Å¾Ã¡nru filmu")
        
        genres = [
            "AkÄnÃ­", "Komedie", "Drama", "Horor", "Sci-Fi", "Fantasy", 
            "RomantickÃ½", "Thriller", "Krimi", "HistorickÃ½", "VÃ¡leÄnÃ½",
            "Å½ivotopisnÃ½", "DobrodruÅ¾nÃ½", "Western", "MysteriÃ³znÃ­"
        ]
        
        selected_genre = st.radio(
            "Vyberte Å¾Ã¡nr pro novÃ½ film:",
            genres,
            horizontal=True
        )
        
        # Generate plot button
        col1, col2 = st.columns([1, 3])
        with col1:
            if st.button("ğŸ¬ Vygenerovat zÃ¡pletku", type="primary"):
                with st.spinner(f"VytvÃ¡Å™Ã­m originÃ¡lnÃ­ zÃ¡pletku pro {selected_genre.lower()} film..."):
                    # Get relevant context from reviews
                    genre_query = f"pozitivnÃ­ recenze {selected_genre.lower()} film dobrÃ½ kvalitnÃ­ oceÅˆovanÃ½"
                    relevant_chunks = retrieve_relevant_chunks(
                        genre_query,
                        st.session_state.embeddings_model,
                        st.session_state.vector_store,
                        st.session_state.document_chunks,
                        k=5
                    )
                    
                    context = "\n\n".join(relevant_chunks) if relevant_chunks else "Å½Ã¡dnÃ½ relevantnÃ­ kontext nebyl nalezen."
                    
                    # Generate plot
                    plot_data = generate_movie_plot(selected_genre, context)
                    
                    # Add to generated plots
                    timestamp = datetime.now().strftime("%d.%m.%Y %H:%M:%S")
                    st.session_state.generated_plots.append({
                        'genre': selected_genre,
                        'plot': plot_data['plot'],
                        'raw_prompt': plot_data['raw_prompt'],
                        'raw_response': plot_data['raw_response'],
                        'is_fallback': plot_data['is_fallback'],
                        'timestamp': timestamp,
                        'context_used': context
                    })
                    
                    st.rerun()
        
        with col2:
            if st.button("ğŸ—‘ï¸ Vymazat vÅ¡echny zÃ¡pletky"):
                st.session_state.generated_plots = []
                st.rerun()
        
        # Display generated plots
        if st.session_state.generated_plots:
            st.subheader("ğŸ“ VygenerovanÃ© zÃ¡pletky")
            
            for i, plot_data in enumerate(reversed(st.session_state.generated_plots)):
                with st.container():
                    st.markdown(f"### ğŸ¬ {plot_data['genre']} film ({plot_data['timestamp']})")
                    st.markdown(plot_data['plot'])
                    
                    # Add expanders for debugging information
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        with st.expander("ğŸ” Zobrazit raw prompt"):
                            st.markdown("**Prompt odeslanÃ½ do LLM:**")
                            st.text(plot_data.get('raw_prompt', 'Prompt nenÃ­ k dispozici'))
                            
                            if 'context_used' in plot_data:
                                st.markdown("**Kontext z recenzÃ­:**")
                                st.text(plot_data['context_used'])
                    
                    with col2:
                        with st.expander("ğŸ¤– Zobrazit raw odpovÄ›Ä LLM"):
                            st.markdown("**Raw odpovÄ›Ä od LLM:**")
                            st.text(plot_data.get('raw_response', 'OdpovÄ›Ä nenÃ­ k dispozici'))
                            
                            # Show additional info
                            if plot_data.get('is_fallback', False):
                                st.warning("âš ï¸ Tato zÃ¡pletka byla vygenerovÃ¡na zÃ¡loÅ¾nÃ­m systÃ©mem")
                            else:
                                st.success("âœ… ZÃ¡pletka vygenerovÃ¡na pomocÃ­ AI")
                    
                    st.markdown("---")
    
    else:
        st.info("ğŸ‘† Nahrajte prosÃ­m PDF dokument s filmovÃ½mi recenzemi v postrannÃ­m panelu!")
        
        # Show example usage
        st.markdown("""
        ### Jak pouÅ¾Ã­vat tuto aplikaci:
        1. **Nahrajte PDF** s filmovÃ½mi recenzemi pomocÃ­ nahrÃ¡vaÄe souborÅ¯ v postrannÃ­m panelu
        2. **PoÄkejte na zpracovÃ¡nÃ­** - aplikace extrahuje text a vytvoÅ™Ã­ embeddings
        3. **Vyberte Å¾Ã¡nr** filmu z nabÃ­dky
        4. **KliknÄ›te na tlaÄÃ­tko** pro vygenerovÃ¡nÃ­ zÃ¡pletky
        5. **ZÃ­skejte originÃ¡lnÃ­ zÃ¡pletku** inspirovanou pozitivnÃ­mi aspekty z recenzÃ­
        
        ### Vlastnosti:
        - ğŸ“„ Extrakce textu z PDF a rozdÄ›lenÃ­ na ÄÃ¡sti
        - ğŸ” SÃ©mantickÃ© vyhledÃ¡vÃ¡nÃ­ pomocÃ­ embeddings
        - ğŸ­ VÃ½bÄ›r z 15 filmovÃ½ch Å¾Ã¡nrÅ¯
        - ğŸ“ GenerovÃ¡nÃ­ originÃ¡lnÃ­ch zÃ¡pletek v ÄeÅ¡tinÄ›
        - ğŸ¬ Inspirace pozitivnÃ­mi aspekty z recenzÃ­
        """)

if __name__ == "__main__":
    main() 